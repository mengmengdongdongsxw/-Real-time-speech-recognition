 Real-time-speech-recognition
3.1 demo的学习
语音识别主要采用科大讯飞平台的实时语音转写API，通过WebSocket协议通讯连接，终端向服务器发送请求和数据，服务器返回相应结果；函数输入pcm音频文件的路径，接收到json字符串，包含关键信息和识别结果在内的字典和列表的混合形式。
该过程包括两个阶段：握手阶段和实时通讯阶段。
3.2 录音识别初版实现（Recording分支部分）
3.2.1 录音的实现
安装Pyaudio库，调用麦克风采集音频信息，并保存在文件中
 
3.2.2 接收的json字符串结果处理
如图所示，在接收到的json字符串中，首先判定type是否为0，采用type==0的最终结果信息，提取命令时间和识别结果两个主要内容。
设置初始时间ts = int(time.time()*100)  （单位10ms）
命令时间
order_ts=初始时间ts+词在句子中的相对时间int(order_list[0][i]/10)（单位10ms）
识别结果采取wp==n时的结果。
当命令时间order_ts 与当前时间 int(time.time()*100) 相等时，输出相应的命令
 
3.2.3 几个小问题
1）结果为空时也会被输出：
增加判定，若为空则不保存，也不输出
2）同一时间多个命令 或 偶尔返回的下一个词的时间在上一个词之前 ：
设置flag_ts，增加判定，每次输出更新为上一命令时间，若下一个命令时间在此之前或相等，则跳过，进入下一个命令等待
3）说出的命令有时识别不出来：
主要是由于说出的命令在语音识别时未能准确翻译，将命令判定词简化，并增加容易误判的结果为判定词之一，增加容错率以提高准确率
部分效果如下：
  
3.3 实时语音控制（第二版）实现（main分支部分）
3.3.1 实时发送语音数据
通过对发送与接收数据格式的对比，实际上每次直接发送了1280个字节的音频数据，读取的音频数据与发送的是相同的，所以建立通讯连接后，将录取音频改为直接发送采样的音频数据片段，从而实现实时控制。在通讯连接时，将通讯的关闭与语音控制的退出通过命令标志全局变量来控制。
 
3.3.2 几个小问题
1）通过语音命令退出语音控制
设置self.flag_order为退出命令的标志，初始化为1，当时识别到“退出”命令时， self.flag_order变为0，从而退出语音控制，停止发送信息并断开通讯连接。
2）硬件问题
树莓派3.5mm接口只能输出，不能输入，因此语音信号需要通过USB接口采集，单独买了一根转换线以实现树莓派的语音信号采集。
